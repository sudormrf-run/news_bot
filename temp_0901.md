## 요약
- 2025-08-29 ~ 2025-09-01 집계. 12개 서브레딧, 544개 트위터, 22개 디스코드(186개 채널, 17,391개 메시지) 스캔. 전체 본문과 메타데이터 검색은 [news.smol.ai](https://news.smol.ai/)에서 확인 가능.
- 신규 행사 안내: [AI Engineer Code Summit](https://apply.ai.engineer) 접수 공지.

---

## AI Twitter Recap — 한 줄 총평
**코딩 보조와 에이전트 실전 도입 신호가 두드러짐. 중국발 초거대 MoE 공개와 온디바이스 VLM 가속이 인프라·모바일 축을 자극.**

- OpenAI 코딩 스택의 IDE 내장화: GPT‑5가 Xcode 26에 “built‑in”으로 통합, Codex 작업 시작 지연이 “step function” 수준으로 개선됐다는 신호([@OpenAIDevs](https://twitter.com/OpenAIDevs), [@gdb](https://twitter.com/gdb)). 실무자 평가는 상반되며, ChatGPT의 GPT‑5가 불필요한 확인 질문을 최소화하도록 설정됐다는 점이 토론을 촉발([@martin_casado](https://twitter.com/martin_casado), [@yanndubs](https://twitter.com/yanndubs)).
- xAI Grok Code Fast 1의 모멘텀: OpenRouter 보드 1위 등극과 “Claude Sonnet 대비 사용량 60%↑” 주장([@elonmusk](https://twitter.com/elonmusk)). Roo Code 평가 90%([@roo_code](https://twitter.com/roo_code)), 무료 프로모 연장에 따른 사용 급증([@veggie_eric](https://twitter.com/veggie_eric)), 에디터(Cline) 통합 품질 개선([@cline](https://twitter.com/cline)). 디버깅/프로토타이핑엔 강하지만 대용량 편집의 견고성은 Claude Code가 우세하다는 지적([@vikhyatk](https://twitter.com/vikhyatk), [@dzhng](https://twitter.com/dzhng), [@QuixiAI](https://twitter.com/QuixiAI)).
- Zhipu GLM‑4.5의 “Claude Code 대비 저가·고빈도” 전략: Claude Code 대비 약 1/7 가격에 3배 프롬프트 제공하는 “GLM Coding Plan” 소개와 52개 실전 과제에서 Claude Sonnet 4 대비 40.4% 승률 주장([@Zai_org](https://twitter.com/Zai_org)). 사용자 경험담도 속도/품질 우수 사례로 보강([@Tim_Dettmers](https://twitter.com/Tim_Dettmers)).
- Meituan LongCat‑Flash‑Chat 공개: 총 560B MoE(평균 활성 ~27B), 층별 MoE·“sink” expert·부하분산 등 상세 기술 보고와 성능 수치 공유(예: >100 tok/s, TerminalBench 39.5, τ²‑Bench 67.7)([announcement](https://twitter.com/Meituan_LongCat/status/), [@reach_vb](https://twitter.com/reach_vb), [@eliebakouch](https://twitter.com/eliebakouch), [analysis](https://twitter.com/)).
- 온디바이스·오픈 VLM: Apple의 FastVLM/MobileCLIP2가 WebGPU로 실시간 로컬 비디오 캡셔닝 구현(“최대 85× 빠르고 3.4× 작다” 주장)([@ClementDelangue](https://twitter.com/ClementDelangue)). 커뮤니티 데모 다수([@_akhaliq](https://twitter.com/_akhaliq)), vLLM은 Kwai Keye‑VL‑1.5 지원 추가([@vllm_project](https://twitter.com/vllm_project)). OpenGVLab의 InternVL 3.5 시리즈 요약도 공유([overview](https://twitter.com/)).
- 에이전트/툴체인/평가: MCP 서버가 인터랙티브 UI 출력 지원(mcp‑ui)([@_avichawla](https://twitter.com/_avichawla), [repo](https://twitter.com/)). Tsinghua의 Self‑Search RL(SSRL) 제안과 성능 비교. vLLM 내부 구조 딥다이브 자료 확산([@gordic_aleksa](https://twitter.com/gordic_aleksa), [@vllm_project](https://twitter.com/vllm_project)).

> 용어 메모 — MoE(전문가 혼합): 여러 전문가 FFN을 라우팅해 부분 활성화로 효율을 올리는 아키텍처. MCP(Model Context Protocol): 모델-도구 간 상호작용 프로토콜, mcp‑ui는 UI 컴포넌트 렌더링을 지원. SSRL(자기검색 강화학습): 모델이 내부 지식 탐색을 모사해 외부 검색 의존도를 낮추려는 학습 기법.

---

## AI Reddit Recap — 한 줄 총평
**로컬/오픈 생태계의 벤치와 출시 소식이 이어진 한편, OpenAI의 보고·티어·보이스 변경 이슈가 정책·제품 신뢰 논쟁을 촉발.**

- 41개 오픈 LLM을 19개 과제로 로컬 벤치마크하고 단순 평균으로 순위를 공개(상위: google/gemma‑3‑12b‑it 등). 전체 아티팩트는 GitHub 제공([I locally benchmarked 41 open-source LLMs across 19 tasks and ranked them](https://i.redd.it/), [jayminban/41-llms-evaluated-on-19-benchmarks](https://github.com/jayminban/41-llms-evaluated-on-19-benchmarks)).
- 130M “truly open‑source” SLM Lille 공개(데이터·가중치·코드·토크나이저·평가 전부 공개). 모델 카드와 리포지토리 공유([I built, pre-trained, and fine-tuned a small language model and it is truly open-source.](https://i.redd.it/), [huggingface.co/Nikity/lille-130m-instruct](https://huggingface.co/Nikity/lille-130m-instruct)).
- OpenAI가 위험 징후가 있는 대화의 인간 검토/법집행기관 보고 가능 경로를 설명하며 논쟁 촉발. 정책/사례 링크와 맥락 정리([People Are Furious That OpenAI Is Reporting ChatGPT Conversations to Law Enforcement](https://www.reddit.com/), [blog post](https://openai.com/), [TechCrunch](https://techcrunch.com/)).
- 기능·성능의 티어링 논쟁: “더 강한 ‘생각 많은’ 모델이 Pro($200/월) 전용” 주장, Plus($20/월) ‘너프’ 불만, 경쟁사·과금 비교와 과거 데모 기능 회수 지적([The real GPT 5 “thinking more” gets locked to pro while plus users continue to be nerfed.](https://www.reddit.com/), [GPT‑4o Spring Update](https://openai.com/), [DevDay “GPTs”/actions](https://openai.com/), [Google One AI Premium](https://one.google.com/), [Claude 3.5 Sonnet](https://www.anthropic.com/)).
- 보이스 제품 재브랜딩과 품질 회귀 이슈: “Advanced Voice → ChatGPT Voice”로 변경, 2025‑09‑09에 standard voice 폐기 예정이라는 배너 캡처 공유, 톤·페르소나 통제력 저하 불만([Oh no. This is fuking upset](https://i.redd.it/)).
- 코드 에이전트 리그(PR Arena) 이미지 기준으로 “OpenAI Codex 87.4%” 등이 회자되나, 에이전트 비교임을 감안해야 한다는 반론과 웹 Codex/CLI 명칭 혼동 지적([openAI nailed it with Codex for devs](https://i.redd.it/), [chatgpt.com/codex](https://chatgpt.com/codex)).
- Jack Clark가 “2026년 말까지 ‘Machines of Loving Grace’가 정의한 ‘powerful AI’에 도달 가능성”을 언급하며 속도 둔화 아님을 주장. 원문과 에세이 링크 제시([Anthropic’s Jack Clark says…](https://www.reddit.com/), [Machines of Loving Grace](https://www.darioamodei.com), [thread](https://x.com/)).

---

## AI Discord Recap — 한 줄 총평
**신규 툴·모델 출시, 최적화 실험, 배포 품질 이슈가 혼재. 실무 워크플로우 정교화와 안전·신뢰 논의가 병행.**

- 비즈니스 자동화·로컬 채팅 도구: 7‑에이전트 평가 파이프라인을 쓰는 Cognitive Dissonance 공개([DSPy-powered 7-agent pipeline](https://betterhuman.tech), [GitHub](https://github.com/)). Apple Silicon 로컬 모델 채팅앱 OpenChat 발표([this tweet](https://x.com/)).
- 대형/중형 모델 동향: Meituan 560B LongCat‑Flash‑Chat 공개와 함께 유럽의 자원 격차 논쟁이 확산([this post](https://xcancel.com)). Nous Research의 Hermes‑4‑14B는 연휴로 화요일로 출시 연기.
- GPU 없이 분산 CPU로 추론: 멀티머신 CPU 추론 프로젝트 공개([GitHub](https://github.com/)). 연구 합성 평가 벤치 DeepScholar‑Bench 소개(최고 성능 <19%)([here](https://xcancel.com)).
- 최적화·시스템 토픽: Reasoning‑Intensive Regression용 경량 옵티마이저 제안([MENTAT paper](https://arxiv.org/)). tinygrad에서 AMD 대역폭 병목 리포트와 병렬 커널 탐색 제안([this GitHub issue](https://github.com/)).
- 품질/운영 이슈: Taco Bell 드라이브스루 AI가 “물 18,000잔” 등 오류 주문을 처리하는 영상이 확산([this X post](https://x.com)). Manus.im에서 크레딧 소모 급증·지원 지연 불만([Manus.im](https://manus.im)).

---

출처: AINews — not much happened today (https://news.smol.ai/issues/25-09-01-not-much)
