#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ìµœì¢… ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸ - í”„ë¡¬í”„íŠ¸ ê°œì„  í™•ì¸
"""

import os
import sys

# src ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from src.config import Config
from src.summarizers.weekly_robotics import WeeklyRoboticsSummarizer
from src.publishers.discord import DiscordPublisher
from src.logger import logger, setup_logger

# ë¡œê±° ì´ˆê¸°í™”
setup_logger(level="INFO")

# í…ŒìŠ¤íŠ¸
summarizer = WeeklyRoboticsSummarizer()
url = "https://www.weeklyrobotics.com/weekly-robotics-315"

print("=" * 60)
print("Weekly Robotics ìµœì¢… í…ŒìŠ¤íŠ¸")
print("=" * 60)

try:
    # 1. ìš”ì•½ ìƒì„± (ìƒˆ í”„ë¡¬í”„íŠ¸ë¡œ)
    print("\n1ï¸âƒ£ ìš”ì•½ ìƒì„± ì¤‘... (í”„ë¡¬í”„íŠ¸ ê°œì„  í™•ì¸)")
    result = summarizer.summarize_with_result(url)
    
    print("\nğŸ“‹ ë©”íƒ€ë°ì´í„°:")
    print(f"  - í—¤ë“œë¼ì¸: {result.metadata.get('headline')}")
    print(f"  - ë‚ ì§œ: {result.metadata.get('date')}")
    
    # 2. ë§í¬ ì¤‘ë³µ í™•ì¸
    print("\n2ï¸âƒ£ ë§í¬ ì¤‘ë³µ ì²´í¬:")
    import re
    links = re.findall(r'\[([^\]]+)\]\(([^)]+)\)', result.summary)
    url_counts = {}
    for text, url in links:
        url_counts[url] = url_counts.get(url, 0) + 1
        
    duplicates = {url: count for url, count in url_counts.items() if count > 1}
    if duplicates:
        print("  âš ï¸ ì¤‘ë³µ ë§í¬ ë°œê²¬:")
        for url, count in duplicates.items():
            print(f"    - {url[:50]}... : {count}ë²ˆ")
    else:
        print("  âœ… ì¤‘ë³µ ë§í¬ ì—†ìŒ")
    
    # 3. Discord ì„ë² ë“œ ë¹„í™œì„±í™” í…ŒìŠ¤íŠ¸
    print("\n3ï¸âƒ£ Discord ë§í¬ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸:")
    discord = DiscordPublisher()
    
    # GitHub URL ì‹œë®¬ë ˆì´ì…˜
    github_url = "https://github.com/orgs/example/discussions/123"
    discord_content = result.summary + f"\n\n---\nğŸ“– **ìƒì„¸ ë‰´ìŠ¤ë ˆí„°**: {github_url}"
    
    # ë§í¬ ì²˜ë¦¬
    processed = discord._disable_link_embeds(discord_content)
    
    # í™•ì¸
    processed_links = re.findall(r'\[([^\]]+)\]\(([^)]+)\)', processed)
    print("  ì²˜ë¦¬ëœ ë§í¬ ì˜ˆì‹œ (ì²« 3ê°œ):")
    for i, (text, url) in enumerate(processed_links[:3]):
        if url.startswith('<') and url.endswith('>'):
            print(f"    âœ… [{text}]({url[:30]}...) - ì„ë² ë“œ ë¹„í™œì„±í™”")
        else:
            print(f"    âš ï¸ [{text}]({url[:30]}...) - ì„ë² ë“œ í™œì„±")
    
    # GitHub ë§í¬ í™•ì¸
    for text, url in processed_links:
        if 'github.com' in url and 'discussions' in url:
            if not (url.startswith('<') and url.endswith('>')):
                print(f"    âœ… GitHub Discussion ë§í¬ëŠ” ì„ë² ë“œ ìœ ì§€: {url[:50]}...")
                break
    
    # 4. ì¶œë ¥ ìƒ˜í”Œ
    print("\n4ï¸âƒ£ ìµœì¢… ì¶œë ¥ ìƒ˜í”Œ (ì²« 800ì):")
    print("-" * 40)
    print(processed[:800])
    print("-" * 40)
    
except Exception as e:
    print(f"âŒ ì—ëŸ¬: {e}")
    import traceback
    traceback.print_exc()

print("\n" + "=" * 60)